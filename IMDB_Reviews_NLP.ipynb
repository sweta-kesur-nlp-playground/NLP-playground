{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh0P8H97uSeZ"
      },
      "source": [
        "**Get Data From Here** :- <a href=\"https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?select=IMDB+Dataset.csv\">Get Data</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z9CJPbeuSea"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ycK3bdRLuSea"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8m9v0fmuSec"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUv7QVSzw34p",
        "outputId": "c166303f-130f-47de-d0c4-eaba136bd8fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a7nJODHiuSec",
        "outputId": "7220c618-7956-4650-a45c-dc9bfcc25880"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0d595660-5f70-4b76-8acd-f8b27e8b5c29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d595660-5f70-4b76-8acd-f8b27e8b5c29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d595660-5f70-4b76-8acd-f8b27e8b5c29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d595660-5f70-4b76-8acd-f8b27e8b5c29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/dataset.csv\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "JoaezMtYuSed",
        "outputId": "8c9ebc1b-5c55-45ba-e0f2-e6a43851ee00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary statistics of numerical features : \n",
            "                                                    review sentiment\n",
            "count                                               50000     50000\n",
            "unique                                              49582         2\n",
            "top     Loved today's show!!! It was a variety and not...  positive\n",
            "freq                                                    5     25000\n",
            "=======================================================================\n",
            "\n",
            "Total number of reviews:  50000\n",
            "=======================================================================\n",
            "\n",
            "Total number of Sentiments:  2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57ea2b90-36e7-4586-9e35-2d07f0d6e308\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ea2b90-36e7-4586-9e35-2d07f0d6e308')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ea2b90-36e7-4586-9e35-2d07f0d6e308 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ea2b90-36e7-4586-9e35-2d07f0d6e308');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      One of the other reviewers has mentioned that ...          1\n",
              "1      A wonderful little production. <br /><br />The...          1\n",
              "2      I thought this was a wonderful way to spend ti...          1\n",
              "3      Basically there's a family where a little boy ...          0\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
              "...                                                  ...        ...\n",
              "49995  I thought this movie did a down right good job...          1\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
              "49997  I am a Catholic taught in parochial elementary...          0\n",
              "49998  I'm going to have to disagree with the previou...          0\n",
              "49999  No one expects the Star Trek movies to be high...          0\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "print(\"Summary statistics of numerical features : \\n\", df.describe())\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "\n",
        "print(\"\\nTotal number of reviews: \",len(df))\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "\n",
        "print(\"\\nTotal number of Sentiments: \", len(list(set(df['sentiment']))))\n",
        "\n",
        "df['sentiment'] = np.where(df['sentiment'] == \"positive\", 1, 0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMrcBweuuSee"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "9_Cut056uSef",
        "outputId": "aad0342b-bb74-4e9f-9bdc-656c5f4e93ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# sns.countplot(df['Rating'])\n",
        "df['sentiment'].value_counts().sort_index().plot(kind='bar',color = 'blue')\n",
        "plt.title('Distribution of Rating')\n",
        "plt.grid()\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"white\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCDkkueAuSeg"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GPDAZT6juSeg",
        "outputId": "87708fef-954f-4045-ef41-ccf132ec914f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ef22fabc-2c40-4b0f-ad9f-d99ca5364a34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11841</th>\n",
              "      <td>John Cassavetes is on the run from the law. He...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19602</th>\n",
              "      <td>It's not just that the movie is lame. It's mor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45519</th>\n",
              "      <td>Well, if it weren't for Ethel Waters and a 7-y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25747</th>\n",
              "      <td>I find Alan Jacobs review very accurate concer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42642</th>\n",
              "      <td>This movie is simply awesome. It is so hilario...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9869</th>\n",
              "      <td>This is an excellent movie that tackles the is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42192</th>\n",
              "      <td>i was kinda interested in this movie as a tras...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12143</th>\n",
              "      <td>I think I am some kind of Road Runner fan. I d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34963</th>\n",
              "      <td>Two years passed and mostly everyone looks dif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23333</th>\n",
              "      <td>I'm really not too sure why people are being s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef22fabc-2c40-4b0f-ad9f-d99ca5364a34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef22fabc-2c40-4b0f-ad9f-d99ca5364a34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef22fabc-2c40-4b0f-ad9f-d99ca5364a34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "11841  John Cassavetes is on the run from the law. He...          1\n",
              "19602  It's not just that the movie is lame. It's mor...          0\n",
              "45519  Well, if it weren't for Ethel Waters and a 7-y...          0\n",
              "25747  I find Alan Jacobs review very accurate concer...          1\n",
              "42642  This movie is simply awesome. It is so hilario...          1\n",
              "...                                                  ...        ...\n",
              "9869   This is an excellent movie that tackles the is...          1\n",
              "42192  i was kinda interested in this movie as a tras...          0\n",
              "12143  I think I am some kind of Road Runner fan. I d...          1\n",
              "34963  Two years passed and mostly everyone looks dif...          1\n",
              "23333  I'm really not too sure why people are being s...          0\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df = df.sample(frac=0.1, random_state=0) #uncomment to use full set of data\n",
        "\n",
        "# Drop missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnT2qvtUuSeh"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDwZJHuNuSeh",
        "outputId": "4cc751ca-e19f-462b-ed4b-ab9d64ef5cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 4500 training examples and 500 validation examples. \n",
            "\n",
            "Show a review in the training set : \n",
            " THE CRIMSON RIVERS is one of the most over-directed, over-the-top, over-everything mess I've ever seen come out of France. There's nothing worse than a French production trying to out-do films made in Hollywood and CR is a perfect example of such a wannabe horror/action/buddy flick. I almost stopped it halfway through because I knew it wouldn't amount to anything but French guys trying to show-off.<br /><br />The film starts off promisingly, like some sort of expansive horror film, but it quickly shifts genres, from horror to action to x-files type to buddy flick, that in the end, CR is all of it and also none of it. It's so full of clichés that at one point I thought the whole thing was a comedy. The painful dialogue and those silent pauses, with fades outs and fades ins just at the right expositionary moments, made me groan. I thought only films made in Hollywood used this hackneyed technique.<br /><br />The chase scene, with Vincent Cassel running after the killer, is so over-directed and over-done that it's almost a thing of beauty. The climax on top of the mountain, with the stupid revelation about the killer(s) with Cassel and Reno playing \"buddies\" like Nolte and Murphy in 48 HRS, completely derailed what little credibility the film had by then.<br /><br />It's difficult to believe that the director of THE CRIMSON RIVERS also directed GOTHIKA, which though had its share of problems, doesn't even come close to the awfulness of this overbaked, confused film.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23499    Paul Naschy as a ghostly security guard in thi...\n",
              " 32754    For every series that makes it to television, ...\n",
              " 41199    I had the displeasure of watching this movie w...\n",
              " 4152     Hear are some of the interesting things our co...\n",
              " 36723    Every time I think about this film I feel phys...\n",
              "                                ...                        \n",
              " 33530    I can not believe such slanted, jingoistic mat...\n",
              " 16729    This movie was rented by a friend. Her choice ...\n",
              " 33642    A British teen movies which centres around a g...\n",
              " 10195    I only gave this film a 4 because I saw it in ...\n",
              " 7520     What a disappointment!<br /><br />This film se...\n",
              " Name: review, Length: 4500, dtype: object, 23499    1\n",
              " 32754    0\n",
              " 41199    0\n",
              " 4152     0\n",
              " 36723    0\n",
              "         ..\n",
              " 33530    0\n",
              " 16729    0\n",
              " 33642    0\n",
              " 10195    0\n",
              " 7520     0\n",
              " Name: sentiment, Length: 4500, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], \\\n",
        "                                                    test_size=0.1, random_state=0)\n",
        "\n",
        "print('Load %d training examples and %d validation examples. \\n' %(X_train.shape[0],X_test.shape[0]))\n",
        "print('Show a review in the training set : \\n', X_train.iloc[10])\n",
        "X_train,y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKhH6dx-uSei"
      },
      "source": [
        "# Bag of Words\n",
        "<br>\n",
        "\n",
        "**Step 1 : Preprocess raw reviews to cleaned reviews**\n",
        "\n",
        "**Step 2 : Create BoW using CountVectorizer / Tfidfvectorizer in sklearn**\n",
        "\n",
        "**Step 3 : Transform review text to numerical representations (feature vectors)**\n",
        "\n",
        "**Step 4 : Fit feature vectors to supervised learning algorithm (eg. Naive Bayes, Logistic regression, etc.)**\n",
        "\n",
        "**Step 5 : Improve the model performance by GridSearch**\n",
        "\n",
        "# Text Preprocessing\n",
        "<br>\n",
        "\n",
        "**Step 1 : remove html tags using BeautifulSoup**\n",
        "\n",
        "**Step 2 : remove non-character such as digits and symbols**\n",
        "\n",
        "**Step 3 : convert to lower case**\n",
        "\n",
        "**Step 4 : remove stop words such as \"the\" and \"and\" if needed**\n",
        "\n",
        "**Step 5 : convert to root words by stemming if needed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NWOOR73OuSei"
      },
      "outputs": [],
      "source": [
        "def cleanText(raw_text, remove_stopwords=False, stemming=False, split_text=False, \\\n",
        "             ):\n",
        "    '''\n",
        "    Convert a raw review to a cleaned review\n",
        "    '''\n",
        "    text = BeautifulSoup(raw_text, 'html.parser').get_text()\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "    words = letters_only.lower().split() \n",
        "    \n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "        \n",
        "    if stemming==True:\n",
        "\n",
        "        stemmer = SnowballStemmer('english') \n",
        "        words = [stemmer.stem(w) for w in words]\n",
        "        \n",
        "    if split_text==True:\n",
        "        return (words)\n",
        "    \n",
        "    return( \" \".join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkV59EMEuSej",
        "outputId": "021f266c-1659-4f91-a59e-d971d404f505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show a cleaned review in the training set : \n",
            " the crimson rivers is one of the most over directed over the top over everything mess i ve ever seen come out of france there s nothing worse than a french production trying to out do films made in hollywood and cr is a perfect example of such a wannabe horror action buddy flick i almost stopped it halfway through because i knew it wouldn t amount to anything but french guys trying to show off the film starts off promisingly like some sort of expansive horror film but it quickly shifts genres from horror to action to x files type to buddy flick that in the end cr is all of it and also none of it it s so full of clich s that at one point i thought the whole thing was a comedy the painful dialogue and those silent pauses with fades outs and fades ins just at the right expositionary moments made me groan i thought only films made in hollywood used this hackneyed technique the chase scene with vincent cassel running after the killer is so over directed and over done that it s almost a thing of beauty the climax on top of the mountain with the stupid revelation about the killer s with cassel and reno playing buddies like nolte and murphy in hrs completely derailed what little credibility the film had by then it s difficult to believe that the director of the crimson rivers also directed gothika which though had its share of problems doesn t even come close to the awfulness of this overbaked confused film\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "from bs4 import BeautifulSoup \n",
        "import logging\n",
        "from wordcloud import WordCloud\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "X_train_cleaned = []\n",
        "X_test_cleaned = []\n",
        "\n",
        "for d in X_train:\n",
        "    X_train_cleaned.append(cleanText(d))\n",
        "print('Show a cleaned review in the training set : \\n',  X_train_cleaned[10])\n",
        "    \n",
        "for d in X_test:\n",
        "    X_test_cleaned.append(cleanText(d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J0liP6puSej"
      },
      "source": [
        "## CountVectorizer with Mulinomial Naive Bayes (Benchmark Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halJ0JOPuSej",
        "outputId": "d27f64a7-753b-4e69-d44b-0276010e007b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features : 36751 \n",
            "\n",
            "Show some feature names : \n",
            " ['aa', 'ameche', 'auggie', 'betrayals', 'bright', 'cathryn', 'clownhouse', 'copying', 'dazzle', 'disarray', 'dvd', 'estimation', 'fighter', 'fusion', 'greenfinch', 'henson', 'imaginings', 'ir', 'kint', 'linklater', 'maropis', 'misik', 'nectar', 'organise', 'performing', 'pre', 'rages', 'reputedly', 'saddled', 'sexiness', 'smith', 'steal', 'swoozie', 'tinfoil', 'unattuned', 'vernacular', 'willed']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "countVect = CountVectorizer() \n",
        "X_train_countVect = countVect.fit_transform(X_train_cleaned)\n",
        "print(\"Number of features : %d \\n\" %len(countVect.get_feature_names())) #6378 \n",
        "print(\"Show some feature names : \\n\", countVect.get_feature_names()[::1000])\n",
        "\n",
        "\n",
        "# Train MultinomialNB classifier\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_countVect, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c7y5OleGuSek"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(countVect,open('countVect_imdb.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O2QE-DYTuSek"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "def modelEvaluation(predictions):\n",
        "    '''\n",
        "    Print model evaluation to predicted result \n",
        "    '''\n",
        "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
        "    print(\"\\nAUC score : {:.4f}\".format(roc_auc_score(y_test, predictions)))\n",
        "    print(\"\\nClassification report : \\n\", metrics.classification_report(y_test, predictions))\n",
        "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18EpbXfmuSel",
        "outputId": "3a3d1c9f-b4ef-4cdd-f270-8b35ae535e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on validation set: 0.8140\n",
            "\n",
            "AUC score : 0.8142\n",
            "\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82       249\n",
            "           1       0.85      0.77      0.81       251\n",
            "\n",
            "    accuracy                           0.81       500\n",
            "   macro avg       0.82      0.81      0.81       500\n",
            "weighted avg       0.82      0.81      0.81       500\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            " [[214  35]\n",
            " [ 58 193]]\n"
          ]
        }
      ],
      "source": [
        "predictions = mnb.predict(countVect.transform(X_test_cleaned))\n",
        "modelEvaluation(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9ZRaRrYnuSel"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(mnb,open('Naive_Bayes_model_imdb.pkl','wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESbsbGTUuSel"
      },
      "source": [
        "# TfidfVectorizer with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7T663xsuSel",
        "outputId": "aa2f3668-0ec5-4707-cb32-c071ea706cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features : 10505 \n",
            "\n",
            "Show some feature names : \n",
            " ['00', 'belonged', 'completion', 'dubious', 'garbage', 'interviewing', 'million', 'plays', 'rough', 'strike', 'vein']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "tfidf = TfidfVectorizer(min_df=5) #minimum document frequency of 5\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "print(\"Number of features : %d \\n\" %len(tfidf.get_feature_names())) #1722\n",
        "print(\"Show some feature names : \\n\", tfidf.get_feature_names()[::1000])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otk5qX3wuSem",
        "outputId": "360a9bc5-5b20-404b-b609-3f2fdbc97259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 features with smallest coefficients :\n",
            "['bad' 'worst' 'awful' 'no' 'waste' 'poor' 'terrible' 'boring' 'even'\n",
            " 'minutes']\n",
            "\n",
            "Top 10 features with largest coefficients : \n",
            "['great' 'and' 'excellent' 'best' 'it' 'wonderful' 'very' 'also' 'well'\n",
            " 'love']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "feature_names = np.array(tfidf.get_feature_names())\n",
        "sorted_coef_index = lr.coef_[0].argsort()\n",
        "print('\\nTop 10 features with smallest coefficients :\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Top 10 features with largest coefficients : \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeGgT2BjuSem",
        "outputId": "8ce712b0-376a-468a-9336-ed2bab4c56a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on validation set: 0.8500\n",
            "\n",
            "AUC score : 0.8500\n",
            "\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       249\n",
            "           1       0.85      0.85      0.85       251\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.85      0.85      0.85       500\n",
            "weighted avg       0.85      0.85      0.85       500\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            " [[211  38]\n",
            " [ 37 214]]\n"
          ]
        }
      ],
      "source": [
        "predictions = lr.predict(tfidf.transform(X_test_cleaned))\n",
        "modelEvaluation(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koXslSfsuSem",
        "outputId": "5f3c5107-123e-480f-8655-30812eed5cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best paramenter set is : \n",
            " {'lr__C': 10, 'tfidf__max_features': None, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None}\n",
            "\n",
            "Accuracy on validation set: 0.8720\n",
            "\n",
            "AUC score : 0.8720\n",
            "\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87       249\n",
            "           1       0.87      0.88      0.87       251\n",
            "\n",
            "    accuracy                           0.87       500\n",
            "   macro avg       0.87      0.87      0.87       500\n",
            "weighted avg       0.87      0.87      0.87       500\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            " [[216  33]\n",
            " [ 31 220]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import  GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "estimators = [(\"tfidf\", TfidfVectorizer()), (\"lr\", LogisticRegression())]\n",
        "model = Pipeline(estimators)\n",
        "\n",
        "\n",
        "params = {\"lr__C\":[0.1, 1, 10], \n",
        "          \"tfidf__min_df\": [1, 3], \n",
        "          \"tfidf__max_features\": [1000, None], \n",
        "          \"tfidf__ngram_range\": [(1,1), (1,2)], \n",
        "          \"tfidf__stop_words\": [None, \"english\"]} \n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid.fit(X_train_cleaned, y_train)\n",
        "print(\"The best paramenter set is : \\n\", grid.best_params_)\n",
        "\n",
        "\n",
        "# Evaluate on the validaton set\n",
        "predictions = grid.predict(X_test_cleaned)\n",
        "modelEvaluation(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeVd4kKiuSen"
      },
      "source": [
        "# Word2Vec\n",
        "<br>\n",
        "\n",
        "**Step 1 : Parse review text to sentences (Word2Vec model takes a list of sentences as inputs)**\n",
        "\n",
        "**Step 2 : Create volcabulary list using Word2Vec model.**\n",
        "\n",
        "**Step 3 : Transform each review into numerical representation by computing average feature vectors of words therein.**\n",
        "\n",
        "**Step 4 : Fit the average feature vectors to Random Forest Classifier.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Eg7BtIuSen",
        "outputId": "67cb01ff-7a51-4519-ec4e-0bdb382964ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "4500 parsed sentence in the training set\n",
            "\n",
            "Show a parsed sentence in the training set : \n",
            " ['the', 'crimson', 'rivers', 'is', 'one', 'of', 'the', 'most', 'over', 'directed', 'over', 'the', 'top', 'over', 'everything', 'mess', 'i', 've', 'ever', 'seen', 'come', 'out', 'of', 'france', 'there', 's', 'nothing', 'worse', 'than', 'a', 'french', 'production', 'trying', 'to', 'out', 'do', 'films', 'made', 'in', 'hollywood', 'and', 'cr', 'is', 'a', 'perfect', 'example', 'of', 'such', 'a', 'wannabe', 'horror', 'action', 'buddy', 'flick', 'i', 'almost', 'stopped', 'it', 'halfway', 'through', 'because', 'i', 'knew', 'it', 'wouldn', 't', 'amount', 'to', 'anything', 'but', 'french', 'guys', 'trying', 'to', 'show', 'off', 'the', 'film', 'starts', 'off', 'promisingly', 'like', 'some', 'sort', 'of', 'expansive', 'horror', 'film', 'but', 'it', 'quickly', 'shifts', 'genres', 'from', 'horror', 'to', 'action', 'to', 'x', 'files', 'type', 'to', 'buddy', 'flick', 'that', 'in', 'the', 'end', 'cr', 'is', 'all', 'of', 'it', 'and', 'also', 'none', 'of', 'it', 'it', 's', 'so', 'full', 'of', 'clich', 's', 'that', 'at', 'one', 'point', 'i', 'thought', 'the', 'whole', 'thing', 'was', 'a', 'comedy', 'the', 'painful', 'dialogue', 'and', 'those', 'silent', 'pauses', 'with', 'fades', 'outs', 'and', 'fades', 'ins', 'just', 'at', 'the', 'right', 'expositionary', 'moments', 'made', 'me', 'groan', 'i', 'thought', 'only', 'films', 'made', 'in', 'hollywood', 'used', 'this', 'hackneyed', 'technique', 'the', 'chase', 'scene', 'with', 'vincent', 'cassel', 'running', 'after', 'the', 'killer', 'is', 'so', 'over', 'directed', 'and', 'over', 'done', 'that', 'it', 's', 'almost', 'a', 'thing', 'of', 'beauty', 'the', 'climax', 'on', 'top', 'of', 'the', 'mountain', 'with', 'the', 'stupid', 'revelation', 'about', 'the', 'killer', 's', 'with', 'cassel', 'and', 'reno', 'playing', 'buddies', 'like', 'nolte', 'and', 'murphy', 'in', 'hrs', 'completely', 'derailed', 'what', 'little', 'credibility', 'the', 'film', 'had', 'by', 'then', 'it', 's', 'difficult', 'to', 'believe', 'that', 'the', 'director', 'of', 'the', 'crimson', 'rivers', 'also', 'directed', 'gothika', 'which', 'though', 'had', 'its', 'share', 'of', 'problems', 'doesn', 't', 'even', 'come', 'close', 'to', 'the', 'awfulness', 'of', 'this', 'overbaked', 'confused', 'film']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "def parseSent(review, tokenizer, remove_stopwords=False):\n",
        "\n",
        "    raw_sentences = tokenizer.tokenize(review.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(cleanText(raw_sentence, remove_stopwords, split_text=True))\n",
        "    return sentences\n",
        "\n",
        "\n",
        "# Parse each review in the training set into sentences\n",
        "sentences = []\n",
        "for review in X_train_cleaned:\n",
        "    sentences += parseSent(review, tokenizer,remove_stopwords=False)\n",
        "    \n",
        "print('%d parsed sentence in the training set\\n'  %len(sentences))\n",
        "print('Show a parsed sentence in the training set : \\n',  sentences[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lkjs__fuSen"
      },
      "source": [
        "## Creating Volcabulary List usinhg Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx2K2qm7uSen",
        "outputId": "40b757eb-0e18-473f-b8d3-e4cec794a91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Word2Vec model ...\n",
            "\n",
            "Number of words in the vocabulary list : 6945 \n",
            "\n",
            "Show first 10 words in the vocalbulary list  vocabulary list: \n",
            " ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n"
          ]
        }
      ],
      "source": [
        "from wordcloud import WordCloud\n",
        "from gensim.models import word2vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "num_features = 300  #embedding dimension                     \n",
        "min_word_count = 10                \n",
        "num_workers = 4       \n",
        "context = 10                                                                                          \n",
        "downsampling = 1e-3 \n",
        "\n",
        "print(\"Training Word2Vec model ...\\n\")\n",
        "w2v = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count,\\\n",
        "                 window = context, sample = downsampling)\n",
        "w2v.init_sims(replace=True)\n",
        "w2v.save(\"w2v_300features_10minwordcounts_10context\") #save trained word2vec model\n",
        "\n",
        "print(\"Number of words in the vocabulary list : %d \\n\" %len(w2v.wv.index2word)) #4016 \n",
        "print(\"Show first 10 words in the vocalbulary list  vocabulary list: \\n\", w2v.wv.index2word[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4CiRZcYuSen"
      },
      "source": [
        "## Averaging Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ccw_YFXUuSeo"
      },
      "outputs": [],
      "source": [
        "def makeFeatureVec(review, model, num_features):\n",
        "    '''\n",
        "    Transform a review to a feature vector by averaging feature vectors of words \n",
        "    appeared in that review and in the volcabulary list created\n",
        "    '''\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    nwords = 0.\n",
        "    index2word_set = set(model.wv.index2word) #index2word is the volcabulary list of the Word2Vec model\n",
        "    isZeroVec = True\n",
        "    for word in review:\n",
        "        if word in index2word_set: \n",
        "            nwords = nwords + 1.\n",
        "            featureVec = np.add(featureVec, model[word])\n",
        "            isZeroVec = False\n",
        "    if isZeroVec == False:\n",
        "        featureVec = np.divide(featureVec, nwords)\n",
        "    return featureVec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZcLZ2cOzuSeo"
      },
      "outputs": [],
      "source": [
        "def getAvgFeatureVecs(reviews, model, num_features):\n",
        "    '''\n",
        "    Transform all reviews to feature vectors using makeFeatureVec()\n",
        "    '''\n",
        "    counter = 0\n",
        "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
        "    for review in reviews:\n",
        "        reviewFeatureVecs[counter] = makeFeatureVec(review, model,num_features)\n",
        "        counter = counter + 1\n",
        "    return reviewFeatureVecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFsEiDBxuSeo",
        "outputId": "2e477d86-5f87-4fb0-9988-79d8bc639731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : 4500 feature vectors with 300 dimensions\n",
            "Validation set : 500 feature vectors with 300 dimensions\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "X_train_cleaned = []\n",
        "for review in X_train:\n",
        "    X_train_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
        "trainVector = getAvgFeatureVecs(X_train_cleaned, w2v, num_features)\n",
        "print(\"Training set : %d feature vectors with %d dimensions\" %trainVector.shape)\n",
        "\n",
        "\n",
        "# Get feature vectors for validation set\n",
        "X_test_cleaned = []\n",
        "for review in X_test:\n",
        "    X_test_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
        "testVector = getAvgFeatureVecs(X_test_cleaned, w2v, num_features)\n",
        "print(\"Validation set : %d feature vectors with %d dimensions\" %testVector.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Jvifx0uSeo"
      },
      "source": [
        "# Random Forest Classifer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvFLw7mduSep",
        "outputId": "13b4eb35-cb02-476e-a038-238d674c3c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on validation set: 0.7640\n",
            "\n",
            "AUC score : 0.7640\n",
            "\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77       249\n",
            "           1       0.77      0.75      0.76       251\n",
            "\n",
            "    accuracy                           0.76       500\n",
            "   macro avg       0.76      0.76      0.76       500\n",
            "weighted avg       0.76      0.76      0.76       500\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            " [[193  56]\n",
            " [ 62 189]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=1000)\n",
        "rf.fit(trainVector, y_train)\n",
        "predictions = rf.predict(testVector)\n",
        "modelEvaluation(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr876XekuSep"
      },
      "source": [
        "## LSTM\n",
        "<br>\n",
        "\n",
        "**Step 1 : Prepare X_train and X_test to 2D tensor.**\n",
        "    \n",
        "**Step 2 : Train a simple LSTM (embeddign layer => LSTM layer => dense layer).**\n",
        "    \n",
        "**Step 3 : Compile and fit the model using log loss function and ADAM optimizer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RgS8udiNuSep"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import defaultdict\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras import backend as K\n",
        "from keras.layers.embeddings import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHd1gpaCuSep",
        "outputId": "d565ecb1-e6e9-4a28-fd72-9555cbcf218c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4500, 200)\n",
            "========================================\n",
            "X_test shape: (500, 200)\n",
            "========================================\n",
            "y_train shape: (4500, 4)\n",
            "========================================\n",
            "y_test shape: (500, 4)\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "top_words = 40000 \n",
        "maxlen = 200 \n",
        "batch_size = 62\n",
        "nb_classes = 4\n",
        "nb_epoch = 6\n",
        "\n",
        "\n",
        "# Vectorize X_train and X_test to 2D tensor\n",
        "tokenizer = Tokenizer(nb_words=top_words) #only consider top 20000 words in the corpse\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "# tokenizer.word_index #access word-to-index dictionary of trained tokenizer\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_seq = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
        "X_test_seq = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
        "\n",
        "\n",
        "# one-hot encoding of y_train and y_test\n",
        "y_train_seq = np_utils.to_categorical(y_train, nb_classes)\n",
        "y_test_seq = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "print('X_train shape:', X_train_seq.shape)\n",
        "print(\"========================================\")\n",
        "print('X_test shape:', X_test_seq.shape)\n",
        "print(\"========================================\")\n",
        "print('y_train shape:', y_train_seq.shape)\n",
        "print(\"========================================\")\n",
        "print('y_test shape:', y_test_seq.shape)\n",
        "print(\"========================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuU0n9c2uSep",
        "outputId": "6a6a19fa-3ebc-4c8c-e7d1-d809d9697033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 128)         5120000   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 128)         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 516       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,252,100\n",
            "Trainable params: 5,252,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(top_words, 128))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) \n",
        "model1.add(Dense(nb_classes))\n",
        "model1.add(Activation('softmax'))\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O03ghyKkuSeq",
        "outputId": "7ce8f7ef-084c-4fbd-9533-ba81bc5cf130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "73/73 [==============================] - 81s 957ms/step - loss: 0.3988 - accuracy: 0.4933\n",
            "Epoch 2/6\n",
            "73/73 [==============================] - 69s 944ms/step - loss: 0.3382 - accuracy: 0.5858\n",
            "Epoch 3/6\n",
            "73/73 [==============================] - 67s 924ms/step - loss: 0.2507 - accuracy: 0.7718\n",
            "Epoch 4/6\n",
            "73/73 [==============================] - 68s 933ms/step - loss: 0.1431 - accuracy: 0.8844\n",
            "Epoch 5/6\n",
            "73/73 [==============================] - 67s 923ms/step - loss: 0.0753 - accuracy: 0.9462\n",
            "Epoch 6/6\n",
            "73/73 [==============================] - 67s 922ms/step - loss: 0.0438 - accuracy: 0.9729\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.3217 - accuracy: 0.7900\n",
            "Test loss : 0.3217\n",
            "Test accuracy : 0.7900\n"
          ]
        }
      ],
      "source": [
        "model1.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_train_seq, y_train_seq, batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "\n",
        "# Model evluation\n",
        "score = model1.evaluate(X_test_seq, y_test_seq, batch_size=batch_size)\n",
        "print('Test loss : {:.4f}'.format(score[0]))\n",
        "print('Test accuracy : {:.4f}'.format(score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9dFBrefuSeq",
        "outputId": "ae432230-8b3b-45f9-83df-d0b655f7cc2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4500, 4500)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(X_train_seq),len(y_train_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVaRU8e6uSeq",
        "outputId": "050ab909-afff-4c82-e96d-34a32f76ff5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of weight matrix in the embedding layer :  (40000, 128)\n",
            "Size of weight matrix in the hidden layer :  (40000, 128)\n",
            "Size of weight matrix in the output layer :  (128, 512)\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of weight matrix in the embedding layer : \", \\\n",
        "      model1.layers[0].get_weights()[0].shape)\n",
        "\n",
        "# get weight matrix of the hidden layer\n",
        "print(\"Size of weight matrix in the hidden layer : \", \\\n",
        "      model1.layers[0].get_weights()[0].shape)\n",
        "\n",
        "# get weight matrix of the output layer\n",
        "print(\"Size of weight matrix in the output layer : \", \\\n",
        "      model1.layers[2].get_weights()[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDcAW8c-uSeq",
        "outputId": "a89aab8d-9772-4398-89db-dc7ec317277d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://5ff64cc7-3c78-4271-a7a9-90d2b61d7517/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://5ff64cc7-3c78-4271-a7a9-90d2b61d7517/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTM object at 0x7f7128116b10> has the same name 'LSTM' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTM'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f712809c310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "pickle.dump(model1,open('model1.pkl','wb'))\n",
        "v2swe = Word2Vec.load(\"w2v_300features_10minwordcounts_10context\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meItroWEuSeq"
      },
      "source": [
        "## LSTM with Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGZM3KQIuSer",
        "outputId": "8ab492b6-3c15-446d-eb20-16c370e1617f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embedding matrix :  (6945, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = w2v.wv.syn0 \n",
        "print(\"Shape of embedding matrix : \", embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyaFP2ofuSer",
        "outputId": "d0e15f90-1d7b-4f12-e640-1a0ee076b54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4500, 300)\n",
            "========================================\n",
            "X_test shape: (500, 300)\n",
            "========================================\n",
            "y_train shape: (4500, 4)\n",
            "========================================\n",
            "y_test shape: (500, 4)\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "top_words = embedding_matrix.shape[0] #4016 \n",
        "maxlen = 300 \n",
        "batch_size = 62\n",
        "nb_classes = 4\n",
        "nb_epoch = 7\n",
        "\n",
        "\n",
        "# Vectorize X_train and X_test to 2D tensor\n",
        "tokenizer = Tokenizer(nb_words=top_words) #only consider top 20000 words in the corpse\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "# tokenizer.word_index #access word-to-index dictionary of trained tokenizer\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_seq1 = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
        "X_test_seq1 = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
        "\n",
        "\n",
        "# one-hot encoding of y_train and y_test\n",
        "y_train_seq1 = np_utils.to_categorical(y_train, nb_classes)\n",
        "y_test_seq1 = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "print('X_train shape:', X_train_seq1.shape)\n",
        "print(\"========================================\")\n",
        "print('X_test shape:', X_test_seq1.shape)\n",
        "print(\"========================================\")\n",
        "print('y_train shape:', y_train_seq1.shape)\n",
        "print(\"========================================\")\n",
        "print('y_test shape:', y_test_seq1.shape)\n",
        "print(\"========================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF2niYiGuSer",
        "outputId": "0a614608-4822-4938-dc1f-1fd007da60f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4500, 4500)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "len(X_train_seq1),len(y_train_seq1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXbjln1xuSer",
        "outputId": "05e6477a-507e-42db-c2e4-41e7ed27d880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 300)         2083500   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               219648    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,303,664\n",
            "Trainable params: 2,303,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_layer = Embedding(embedding_matrix.shape[0], #4016\n",
        "                            embedding_matrix.shape[1], #300\n",
        "                            weights=[embedding_matrix])\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(embedding_layer)\n",
        "model2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) \n",
        "model2.add(Dense(nb_classes))\n",
        "model2.add(Activation('softmax'))\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fJNc2RMuSer",
        "outputId": "f0a885e0-95ee-43ca-9825-41ad875e722c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "73/73 [==============================] - 145s 2s/step - loss: 0.3809 - accuracy: 0.5056\n",
            "Epoch 2/7\n",
            "73/73 [==============================] - 133s 2s/step - loss: 0.3286 - accuracy: 0.6269\n",
            "Epoch 3/7\n",
            "73/73 [==============================] - 133s 2s/step - loss: 0.2340 - accuracy: 0.7976\n",
            "Epoch 4/7\n",
            "73/73 [==============================] - 132s 2s/step - loss: 0.1725 - accuracy: 0.8569\n",
            "Epoch 5/7\n",
            "73/73 [==============================] - 131s 2s/step - loss: 0.1006 - accuracy: 0.9258\n",
            "Epoch 6/7\n",
            "73/73 [==============================] - 132s 2s/step - loss: 0.0682 - accuracy: 0.9538\n",
            "Epoch 7/7\n",
            "73/73 [==============================] - 132s 2s/step - loss: 0.0386 - accuracy: 0.9778\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.2977 - accuracy: 0.8080\n",
            "Test loss : 0.2977\n",
            "Test accuracy : 0.8080\n"
          ]
        }
      ],
      "source": [
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train_seq1, y_train_seq1, batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "\n",
        "# Model evaluation\n",
        "score = model2.evaluate(X_test_seq1, y_test_seq1, batch_size=batch_size)\n",
        "print('Test loss : {:.4f}'.format(score[0]))\n",
        "print('Test accuracy : {:.4f}'.format(score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1jpudSmuSer",
        "outputId": "0701d0d5-22f7-47d2-832f-ecee35bc75cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of weight matrix in the embedding layer :  (6945, 300)\n",
            "Size of weight matrix in the hidden layer :  (300, 512)\n",
            "Size of weight matrix in the output layer :  (128, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of weight matrix in the embedding layer : \", \\\n",
        "      model2.layers[0].get_weights()[0].shape) \n",
        "\n",
        "print(\"Size of weight matrix in the hidden layer : \", \\\n",
        "      model2.layers[1].get_weights()[0].shape) \n",
        "\n",
        "print(\"Size of weight matrix in the output layer : \", \\\n",
        "      model2.layers[2].get_weights()[0].shape) "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "IMDB Reviews NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}